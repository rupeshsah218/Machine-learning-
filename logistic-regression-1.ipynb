{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12875555,"sourceType":"datasetVersion","datasetId":8145050}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve\nimport caas_jupyter_tools as jt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T15:10:36.644003Z","iopub.execute_input":"2025-08-26T15:10:36.644402Z","iopub.status.idle":"2025-08-26T15:10:36.649812Z","shell.execute_reply.started":"2025-08-26T15:10:36.644375Z","shell.execute_reply":"2025-08-26T15:10:36.648829Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df=pd.read_excel(\"/kaggle/input/logistic-regression-hw/Employee.xlsx\")\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T15:08:40.248710Z","iopub.execute_input":"2025-08-26T15:08:40.249060Z","iopub.status.idle":"2025-08-26T15:08:41.664224Z","shell.execute_reply.started":"2025-08-26T15:08:40.249018Z","shell.execute_reply":"2025-08-26T15:08:41.663327Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      Education  JoiningYear       City  PaymentTier  Age  Gender EverBenched  \\\n0     Bachelors         2017  Bangalore            3   34    Male          No   \n1     Bachelors         2013       Pune            1   28  Female          No   \n2     Bachelors         2014  New Delhi            3   38  Female          No   \n3       Masters         2016  Bangalore            3   27    Male          No   \n4       Masters         2017       Pune            3   24    Male         Yes   \n...         ...          ...        ...          ...  ...     ...         ...   \n4648  Bachelors         2013  Bangalore            3   26  Female          No   \n4649    Masters         2013       Pune            2   37    Male          No   \n4650    Masters         2018  New Delhi            3   27    Male          No   \n4651  Bachelors         2012  Bangalore            3   30    Male         Yes   \n4652  Bachelors         2015  Bangalore            3   33    Male         Yes   \n\n      ExperienceInCurrentDomain  LeaveOrNot  \n0                             0           0  \n1                             3           1  \n2                             2           0  \n3                             5           1  \n4                             2           1  \n...                         ...         ...  \n4648                          4           0  \n4649                          2           1  \n4650                          5           1  \n4651                          2           0  \n4652                          4           0  \n\n[4653 rows x 9 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Education</th>\n      <th>JoiningYear</th>\n      <th>City</th>\n      <th>PaymentTier</th>\n      <th>Age</th>\n      <th>Gender</th>\n      <th>EverBenched</th>\n      <th>ExperienceInCurrentDomain</th>\n      <th>LeaveOrNot</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bachelors</td>\n      <td>2017</td>\n      <td>Bangalore</td>\n      <td>3</td>\n      <td>34</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Bachelors</td>\n      <td>2013</td>\n      <td>Pune</td>\n      <td>1</td>\n      <td>28</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bachelors</td>\n      <td>2014</td>\n      <td>New Delhi</td>\n      <td>3</td>\n      <td>38</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Masters</td>\n      <td>2016</td>\n      <td>Bangalore</td>\n      <td>3</td>\n      <td>27</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Masters</td>\n      <td>2017</td>\n      <td>Pune</td>\n      <td>3</td>\n      <td>24</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4648</th>\n      <td>Bachelors</td>\n      <td>2013</td>\n      <td>Bangalore</td>\n      <td>3</td>\n      <td>26</td>\n      <td>Female</td>\n      <td>No</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4649</th>\n      <td>Masters</td>\n      <td>2013</td>\n      <td>Pune</td>\n      <td>2</td>\n      <td>37</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4650</th>\n      <td>Masters</td>\n      <td>2018</td>\n      <td>New Delhi</td>\n      <td>3</td>\n      <td>27</td>\n      <td>Male</td>\n      <td>No</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4651</th>\n      <td>Bachelors</td>\n      <td>2012</td>\n      <td>Bangalore</td>\n      <td>3</td>\n      <td>30</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4652</th>\n      <td>Bachelors</td>\n      <td>2015</td>\n      <td>Bangalore</td>\n      <td>3</td>\n      <td>33</td>\n      <td>Male</td>\n      <td>Yes</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>4653 rows Ã— 9 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"target_candidates = [c for c in df.columns if c.lower() in (\"left\",\"attrition\",\"resigned\",\"is_left\")]\nprint(\"\\nDetected target-like columns:\", target_candidates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T15:11:01.079996Z","iopub.execute_input":"2025-08-26T15:11:01.080479Z","iopub.status.idle":"2025-08-26T15:11:01.086508Z","shell.execute_reply.started":"2025-08-26T15:11:01.080449Z","shell.execute_reply":"2025-08-26T15:11:01.085494Z"}},"outputs":[{"name":"stdout","text":"\nDetected target-like columns: []\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"if 'left' in df.columns:\n    target = 'left'\nelif target_candidates:\n    target = target_candidates[0]\nelse:\n    # try common 'Attrition' variants\n    if 'Attrition' in df.columns:\n        target = 'Attrition'\n    else:\n        # fallback: if there's a column with values 0/1 we might choose it; else raise\n        binary_cols = [c for c in df.columns if df[c].nunique()<=3 and set(df[c].dropna().unique()).issubset({0,1,2})]\n        if binary_cols:\n            target = binary_cols[0]\n        else:\n            raise ValueError(\"Couldn't detect a target column automatically. Expected a 'left' or similar column.\")\n\nprint(\"\\nUsing target column:\", target)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T15:16:58.881625Z","iopub.execute_input":"2025-08-26T15:16:58.881930Z","iopub.status.idle":"2025-08-26T15:16:58.903217Z","shell.execute_reply.started":"2025-08-26T15:16:58.881907Z","shell.execute_reply":"2025-08-26T15:16:58.902278Z"}},"outputs":[{"name":"stdout","text":"\nUsing target column: LeaveOrNot\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"print(\"\\nTarget value counts:\\n\", df[target].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T15:17:16.512079Z","iopub.execute_input":"2025-08-26T15:17:16.512379Z","iopub.status.idle":"2025-08-26T15:17:16.522637Z","shell.execute_reply.started":"2025-08-26T15:17:16.512357Z","shell.execute_reply":"2025-08-26T15:17:16.521570Z"}},"outputs":[{"name":"stdout","text":"\nTarget value counts:\n LeaveOrNot\n0    3053\n1    1600\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"numeric = df.select_dtypes(include=[np.number]).columns.tolist()\nif target in numeric:\n    numeric_no_target = [c for c in numeric if c!=target]\nelse:\n    numeric_no_target = numeric\ncorrs = df[numeric_no_target + [target]].corr()[target].drop(target).sort_values(key=lambda x: x.abs(), ascending=False)\nprint(\"\\nNumeric features correlation with target (sorted by absolute value):\\n\", corrs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-26T15:17:36.268223Z","iopub.execute_input":"2025-08-26T15:17:36.269065Z","iopub.status.idle":"2025-08-26T15:17:36.282990Z","shell.execute_reply.started":"2025-08-26T15:17:36.269011Z","shell.execute_reply":"2025-08-26T15:17:36.282091Z"}},"outputs":[{"name":"stdout","text":"\nNumeric features correlation with target (sorted by absolute value):\n PaymentTier                 -0.197638\nJoiningYear                  0.181705\nAge                         -0.051126\nExperienceInCurrentDomain   -0.030504\nName: LeaveOrNot, dtype: float64\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"corr_df = corrs.reset_index().rename(columns={'index':'feature', target:'corr_with_target'})\njt.display_dataframe_to_user(\"Correlation with target\", corr_df)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"salary_cols = [c for c in df.columns if 'salary' in c.lower()]\ndept_cols = [c for c in df.columns if 'dept' in c.lower() or 'department' in c.lower()]\n\nsalary_col = salary_cols[0] if salary_cols else None\ndept_col = dept_cols[0] if dept_cols else None\n\nprint(\"\\nDetected salary column:\", salary_col)\nprint(\"Detected department column:\", dept_col)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if salary_col:\n    salary_group = df.groupby([salary_col, target]).size().unstack(fill_value=0)\n    salary_group['total'] = salary_group.sum(axis=1)\n    salary_group['prop_left'] = salary_group.get(1, 0) / salary_group['total'] if 1 in salary_group.columns else 0\n    display_df = salary_group.copy()\n    jt.display_dataframe_to_user(\"Salary vs retention counts & proportions\", display_df.reset_index())\n    # Plot bar chart: counts of left vs stayed per salary\n    ax = salary_group.drop(columns=['total','prop_left'], errors='ignore').plot(kind='bar', figsize=(7,4))\n    ax.set_title(\"Counts by Salary and Retention (target={})\".format(target))\n    ax.set_xlabel(\"Salary\")\n    ax.set_ylabel(\"Count\")\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ax = salary_group['prop_left'].plot(kind='bar', figsize=(6,3))\n    ax.set_title(\"Proportion left by Salary\")\n    ax.set_ylabel(\"Proportion left\")\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"No salary-like column detected; skipping salary plots.\")\n\nif dept_col:\n    dept_group = df.groupby([dept_col, target]).size().unstack(fill_value=0)\n    dept_group['total'] = dept_group.sum(axis=1)\n    dept_group['prop_left'] = dept_group.get(1, 0) / dept_group['total'] if 1 in dept_group.columns else 0\n    jt.display_dataframe_to_user(\"Department vs retention counts & proportions\", dept_group.reset_index())\n    ax = dept_group.drop(columns=['total','prop_left'], errors='ignore').plot(kind='bar', figsize=(10,4))\n    ax.set_title(\"Counts by Department and Retention (target={})\".format(target))\n    ax.set_xlabel(\"Department\")\n    ax.set_ylabel(\"Count\")\n    plt.tight_layout()\n    plt.show()\n\n    ax = dept_group['prop_left'].plot(kind='bar', figsize=(10,3))\n    ax.set_title(\"Proportion left by Department\")\n    ax.set_ylabel(\"Proportion left\")\n    plt.tight_layout()\n    plt.show()\nelse:\n    print(\"No department-like column detected; skipping department plots.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"abs_corr = corrs.abs()\nselected_numeric = abs_corr[abs_corr >= 0.10].index.tolist()\nif len(selected_numeric) == 0:\n    selected_numeric = abs_corr.index.tolist()[:5]\nprint(\"\\nSelected numeric features for modelling:\", selected_numeric)\n\nselected_features = selected_numeric.copy()\nif salary_col:\n    selected_features.append(salary_col)\nif dept_col:\n    selected_features.append(dept_col)\n\nprint(\"\\nFinal selected features:\", selected_features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = df[selected_features].copy()\ny = df[target].copy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"numeric_features = [c for c in selected_numeric if c in X.columns]\ncat_features = [c for c in X.columns if c not in numeric_features]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"salary_enc = None\nif salary_col and salary_col in cat_features:\n    # try to detect order\n    uniq = [str(x).lower() for x in sorted(df[salary_col].dropna().unique(), key=str)]\n    # common mapping\n    order = None\n    if set(['low','medium','high']).issubset(set(uniq)):\n        order = ['low','medium','high']\n    if order:\n        cat_transformer = ColumnTransformer(transformers=[\n            ('salary_ord', OrdinalEncoder(categories=[order]), [salary_col]),\n            ('dept_ohe', OneHotEncoder(handle_unknown='ignore', sparse=False), [dept_col]) if dept_col and dept_col in cat_features else ('drop', 'drop', [])\n        ], remainder='drop')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"      preprocessor = ColumnTransformer(transformers=[\n            ('num', StandardScaler(), numeric_features),\n            ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_features)\n        ], remainder='drop')\n    else:\n        preprocessor = ColumnTransformer(transformers=[\n            ('num', StandardScaler(), numeric_features),\n            ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_features)\n        ], remainder='drop')\nelse:\n    preprocessor = ColumnTransformer(transformers=[\n        ('num', StandardScaler(), numeric_features),\n        ('cat', OneHotEncoder(handle_unknown='ignore', sparse=False), cat_features)\n    ], remainder='drop')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipe = Pipeline([\n    ('pre', preprocessor),\n    ('clf', LogisticRegression(max_iter=1000))\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pipe.fit(X_train, y_train)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred = pipe.predict(X_test)\ny_proba = pipe.predict_proba(X_test)[:,1] if hasattr(pipe.named_steps['clf'], \"predict_proba\") else None\n\nacc = accuracy_score(y_test, y_pred)\ncm = confusion_matrix(y_test, y_pred)\nclf_report = classification_report(y_test, y_pred, digits=4)\nroc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else None\n\nprint(\"\\nModel performance on test set:\")\nprint(\"Accuracy:\", acc)\nif roc_auc is not None:\n    print(\"ROC AUC:\", roc_auc)\nprint(\"\\nConfusion Matrix:\\n\", cm)\nprint(\"\\nClassification Report:\\n\", clf_report)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_names = []\npre = pipe.named_steps['pre']\n# Numeric names\nif numeric_features:\n    feature_names += numeric_features\n# Categorical names from OneHotEncoder if used\nif cat_features:\n    # find transformer\n    # we used ColumnTransformer with a 'cat' transformer named 'cat'\n    for name, trans, cols in pre.transformers_:\n        if name == 'cat':\n            ohe = trans\n            # handle when sparse=False else get_feature_names_out\n            try:\n                cat_names = ohe.get_feature_names_out(cols).tolist()\n            except Exception:\n                cat_names = []\n            feature_names += cat_names\n            break\n\ncoef = pipe.named_steps['clf'].coef_[0]\ncoef_df = pd.DataFrame({'feature': feature_names, 'coefficient': coef}).sort_values(by='coefficient', key=lambda x: x.abs(), ascending=False)\njt.display_dataframe_to_user(\"Model coefficients (approx)\", coef_df.head(40))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if y_proba is not None:\n    fpr, tpr, _ = roc_curve(y_test, y_proba)\n    plt.figure(figsize=(6,4))\n    plt.plot(fpr, tpr)\n    plt.plot([0,1],[0,1],'--')\n    plt.title(\"ROC Curve (AUC = {:.4f})\".format(roc_auc))\n    plt.xlabel(\"False Positive Rate\")\n    plt.ylabel(\"True Positive Rate\")\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nSUMMARY:\")\nprint(\"- Detected target column: {}\".format(target))\nprint(\"- Numeric features with strongest correlation to the target (absolute value, top listed above).\")\nprint(\"- Salary and Department (if present) plotted above showing counts and proportions of employees who left.\")\nprint(\"- Final model used features: {}\".format(selected_features))\nprint(\"- Test accuracy: {:.4f}\".format(acc))\nif roc_auc is not None:\n    print(\"- Test ROC AUC: {:.4f}\".format(roc_auc))\nprint(\"\\nFiles created: None. All outputs displayed inline.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}