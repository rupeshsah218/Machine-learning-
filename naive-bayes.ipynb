{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13155278,"sourceType":"datasetVersion","datasetId":8335209}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T06:58:33.183601Z","iopub.execute_input":"2025-09-24T06:58:33.183910Z","iopub.status.idle":"2025-09-24T06:58:38.025432Z","shell.execute_reply.started":"2025-09-24T06:58:33.183880Z","shell.execute_reply":"2025-09-24T06:58:38.024433Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/practice-10/WineQT.csv.csv\")\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T06:59:14.340146Z","iopub.execute_input":"2025-09-24T06:59:14.340530Z","iopub.status.idle":"2025-09-24T06:59:14.413297Z","shell.execute_reply.started":"2025-09-24T06:59:14.340504Z","shell.execute_reply":"2025-09-24T06:59:14.412268Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0               7.4             0.700         0.00             1.9      0.076   \n1               7.8             0.880         0.00             2.6      0.098   \n2               7.8             0.760         0.04             2.3      0.092   \n3              11.2             0.280         0.56             1.9      0.075   \n4               7.4             0.700         0.00             1.9      0.076   \n...             ...               ...          ...             ...        ...   \n1138            6.3             0.510         0.13             2.3      0.076   \n1139            6.8             0.620         0.08             1.9      0.068   \n1140            6.2             0.600         0.08             2.0      0.090   \n1141            5.9             0.550         0.10             2.2      0.062   \n1142            5.9             0.645         0.12             2.0      0.075   \n\n      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                    11.0                  34.0  0.99780  3.51       0.56   \n1                    25.0                  67.0  0.99680  3.20       0.68   \n2                    15.0                  54.0  0.99700  3.26       0.65   \n3                    17.0                  60.0  0.99800  3.16       0.58   \n4                    11.0                  34.0  0.99780  3.51       0.56   \n...                   ...                   ...      ...   ...        ...   \n1138                 29.0                  40.0  0.99574  3.42       0.75   \n1139                 28.0                  38.0  0.99651  3.42       0.82   \n1140                 32.0                  44.0  0.99490  3.45       0.58   \n1141                 39.0                  51.0  0.99512  3.52       0.76   \n1142                 32.0                  44.0  0.99547  3.57       0.71   \n\n      alcohol  quality    Id  \n0         9.4        5     0  \n1         9.8        5     1  \n2         9.8        5     2  \n3         9.8        6     3  \n4         9.4        5     4  \n...       ...      ...   ...  \n1138     11.0        6  1592  \n1139      9.5        6  1593  \n1140     10.5        5  1594  \n1141     11.2        6  1595  \n1142     10.2        5  1597  \n\n[1143 rows x 13 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fixed acidity</th>\n      <th>volatile acidity</th>\n      <th>citric acid</th>\n      <th>residual sugar</th>\n      <th>chlorides</th>\n      <th>free sulfur dioxide</th>\n      <th>total sulfur dioxide</th>\n      <th>density</th>\n      <th>pH</th>\n      <th>sulphates</th>\n      <th>alcohol</th>\n      <th>quality</th>\n      <th>Id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.8</td>\n      <td>0.880</td>\n      <td>0.00</td>\n      <td>2.6</td>\n      <td>0.098</td>\n      <td>25.0</td>\n      <td>67.0</td>\n      <td>0.99680</td>\n      <td>3.20</td>\n      <td>0.68</td>\n      <td>9.8</td>\n      <td>5</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7.8</td>\n      <td>0.760</td>\n      <td>0.04</td>\n      <td>2.3</td>\n      <td>0.092</td>\n      <td>15.0</td>\n      <td>54.0</td>\n      <td>0.99700</td>\n      <td>3.26</td>\n      <td>0.65</td>\n      <td>9.8</td>\n      <td>5</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11.2</td>\n      <td>0.280</td>\n      <td>0.56</td>\n      <td>1.9</td>\n      <td>0.075</td>\n      <td>17.0</td>\n      <td>60.0</td>\n      <td>0.99800</td>\n      <td>3.16</td>\n      <td>0.58</td>\n      <td>9.8</td>\n      <td>6</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7.4</td>\n      <td>0.700</td>\n      <td>0.00</td>\n      <td>1.9</td>\n      <td>0.076</td>\n      <td>11.0</td>\n      <td>34.0</td>\n      <td>0.99780</td>\n      <td>3.51</td>\n      <td>0.56</td>\n      <td>9.4</td>\n      <td>5</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1138</th>\n      <td>6.3</td>\n      <td>0.510</td>\n      <td>0.13</td>\n      <td>2.3</td>\n      <td>0.076</td>\n      <td>29.0</td>\n      <td>40.0</td>\n      <td>0.99574</td>\n      <td>3.42</td>\n      <td>0.75</td>\n      <td>11.0</td>\n      <td>6</td>\n      <td>1592</td>\n    </tr>\n    <tr>\n      <th>1139</th>\n      <td>6.8</td>\n      <td>0.620</td>\n      <td>0.08</td>\n      <td>1.9</td>\n      <td>0.068</td>\n      <td>28.0</td>\n      <td>38.0</td>\n      <td>0.99651</td>\n      <td>3.42</td>\n      <td>0.82</td>\n      <td>9.5</td>\n      <td>6</td>\n      <td>1593</td>\n    </tr>\n    <tr>\n      <th>1140</th>\n      <td>6.2</td>\n      <td>0.600</td>\n      <td>0.08</td>\n      <td>2.0</td>\n      <td>0.090</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99490</td>\n      <td>3.45</td>\n      <td>0.58</td>\n      <td>10.5</td>\n      <td>5</td>\n      <td>1594</td>\n    </tr>\n    <tr>\n      <th>1141</th>\n      <td>5.9</td>\n      <td>0.550</td>\n      <td>0.10</td>\n      <td>2.2</td>\n      <td>0.062</td>\n      <td>39.0</td>\n      <td>51.0</td>\n      <td>0.99512</td>\n      <td>3.52</td>\n      <td>0.76</td>\n      <td>11.2</td>\n      <td>6</td>\n      <td>1595</td>\n    </tr>\n    <tr>\n      <th>1142</th>\n      <td>5.9</td>\n      <td>0.645</td>\n      <td>0.12</td>\n      <td>2.0</td>\n      <td>0.075</td>\n      <td>32.0</td>\n      <td>44.0</td>\n      <td>0.99547</td>\n      <td>3.57</td>\n      <td>0.71</td>\n      <td>10.2</td>\n      <td>5</td>\n      <td>1597</td>\n    </tr>\n  </tbody>\n</table>\n<p>1143 rows Ã— 13 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"print(\"Dataset shape:\", df.shape)\nprint(\"\\nFirst few rows:\")\nprint(df.head())\nprint(\"\\nQuality distribution:\")\nprint(df['quality'].value_counts().sort_index())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T06:59:36.303653Z","iopub.execute_input":"2025-09-24T06:59:36.303968Z","iopub.status.idle":"2025-09-24T06:59:36.328313Z","shell.execute_reply.started":"2025-09-24T06:59:36.303946Z","shell.execute_reply":"2025-09-24T06:59:36.327140Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (1143, 13)\n\nFirst few rows:\n   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n0            7.4              0.70         0.00             1.9      0.076   \n1            7.8              0.88         0.00             2.6      0.098   \n2            7.8              0.76         0.04             2.3      0.092   \n3           11.2              0.28         0.56             1.9      0.075   \n4            7.4              0.70         0.00             1.9      0.076   \n\n   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n0                 11.0                  34.0   0.9978  3.51       0.56   \n1                 25.0                  67.0   0.9968  3.20       0.68   \n2                 15.0                  54.0   0.9970  3.26       0.65   \n3                 17.0                  60.0   0.9980  3.16       0.58   \n4                 11.0                  34.0   0.9978  3.51       0.56   \n\n   alcohol  quality  Id  \n0      9.4        5   0  \n1      9.8        5   1  \n2      9.8        5   2  \n3      9.8        6   3  \n4      9.4        5   4  \n\nQuality distribution:\nquality\n3      6\n4     33\n5    483\n6    462\n7    143\n8     16\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"def categorize_quality(quality):\n    if quality <= 4:\n        return 'Low'\n    elif quality <= 6:\n        return 'Medium'\n    else:\n        return 'High'\n\ndf['quality_category'] = df['quality'].apply(categorize_quality)\n\nprint(\"\\nQuality categories distribution:\")\nprint(df['quality_category'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:00:03.521177Z","iopub.execute_input":"2025-09-24T07:00:03.521728Z","iopub.status.idle":"2025-09-24T07:00:03.533461Z","shell.execute_reply.started":"2025-09-24T07:00:03.521701Z","shell.execute_reply":"2025-09-24T07:00:03.531746Z"}},"outputs":[{"name":"stdout","text":"\nQuality categories distribution:\nquality_category\nMedium    945\nHigh      159\nLow        39\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"X = df.drop(['quality', 'quality_category', 'Id'], axis=1)\ny = df['quality_category']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:00:27.607093Z","iopub.execute_input":"2025-09-24T07:00:27.607477Z","iopub.status.idle":"2025-09-24T07:00:27.617871Z","shell.execute_reply.started":"2025-09-24T07:00:27.607450Z","shell.execute_reply":"2025-09-24T07:00:27.616593Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:00:45.228193Z","iopub.execute_input":"2025-09-24T07:00:45.228612Z","iopub.status.idle":"2025-09-24T07:00:45.254692Z","shell.execute_reply.started":"2025-09-24T07:00:45.228581Z","shell.execute_reply":"2025-09-24T07:00:45.253060Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n\nprint(f\"\\nTraining set size: {X_train.shape}\")\nprint(f\"Test set size: {X_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:00:59.166237Z","iopub.execute_input":"2025-09-24T07:00:59.166853Z","iopub.status.idle":"2025-09-24T07:00:59.189379Z","shell.execute_reply.started":"2025-09-24T07:00:59.166815Z","shell.execute_reply":"2025-09-24T07:00:59.187118Z"}},"outputs":[{"name":"stdout","text":"\nTraining set size: (800, 11)\nTest set size: (343, 11)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB, MultinomialNB","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:01:19.522395Z","iopub.execute_input":"2025-09-24T07:01:19.522799Z","iopub.status.idle":"2025-09-24T07:01:19.539711Z","shell.execute_reply.started":"2025-09-24T07:01:19.522774Z","shell.execute_reply":"2025-09-24T07:01:19.538586Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:01:32.156141Z","iopub.execute_input":"2025-09-24T07:01:32.156545Z","iopub.status.idle":"2025-09-24T07:01:32.181886Z","shell.execute_reply.started":"2025-09-24T07:01:32.156521Z","shell.execute_reply":"2025-09-24T07:01:32.180755Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"GAUSSIAN NAIVE BAYES\")\nprint(\"=\"*50)\n\ngaussian_nb = GaussianNB()\ngaussian_nb.fit(X_train_scaled, y_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:01:50.556650Z","iopub.execute_input":"2025-09-24T07:01:50.557057Z","iopub.status.idle":"2025-09-24T07:01:50.579616Z","shell.execute_reply.started":"2025-09-24T07:01:50.557030Z","shell.execute_reply":"2025-09-24T07:01:50.578256Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nGAUSSIAN NAIVE BAYES\n==================================================\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"GaussianNB()","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"y_pred_multinomial = gaussian_nb.predict(X_test_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:02:10.051148Z","iopub.execute_input":"2025-09-24T07:02:10.051714Z","iopub.status.idle":"2025-09-24T07:02:10.062339Z","shell.execute_reply.started":"2025-09-24T07:02:10.051680Z","shell.execute_reply":"2025-09-24T07:02:10.061279Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"accuracy_multinomial = accuracy_score(y_test, y_pred_multinomial)\nprint(f\"Accuracy: {accuracy_multinomial:.4f}\")\nprint(f\"Classification Report:\\n{classification_report(y_test, y_pred_multinomial)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:02:25.105909Z","iopub.execute_input":"2025-09-24T07:02:25.106251Z","iopub.status.idle":"2025-09-24T07:02:25.128505Z","shell.execute_reply.started":"2025-09-24T07:02:25.106229Z","shell.execute_reply":"2025-09-24T07:02:25.126869Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.7726\nClassification Report:\n              precision    recall  f1-score   support\n\n        High       0.40      0.65      0.50        48\n         Low       0.29      0.17      0.21        12\n      Medium       0.90      0.82      0.86       283\n\n    accuracy                           0.77       343\n   macro avg       0.53      0.54      0.52       343\nweighted avg       0.81      0.77      0.78       343\n\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"MODEL COMPARISON\")\nprint(\"=\"*50)\n\nprint(f\"Gaussian Naive Bayes Accuracy: {accuracy_multinomial:.4f}\")\nprint(f\"Multinomial Naive Bayes Accuracy: {accuracy_multinomial:.4f}\")\n\nif accuracy_multinomial > accuracy_multinomial:\n    print(\"âœ“ Gaussian Naive Bayes performs better!\")\n    best_model = accuracy_multinomial\n    best_scaler = scaler\n    use_scaled = True\nelse:\n    print(\"âœ“ Multinomial Naive Bayes performs better!\")\n    best_model = accuracy_multinomial\n    best_scaler = scaler\n    use_scaled = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:36:38.536862Z","iopub.execute_input":"2025-09-24T07:36:38.537176Z","iopub.status.idle":"2025-09-24T07:36:38.545602Z","shell.execute_reply.started":"2025-09-24T07:36:38.537155Z","shell.execute_reply":"2025-09-24T07:36:38.544250Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nMODEL COMPARISON\n==================================================\nGaussian Naive Bayes Accuracy: 0.7726\nMultinomial Naive Bayes Accuracy: 0.7726\nâœ“ Multinomial Naive Bayes performs better!\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"MODEL COMPARISON\")\nprint(\"=\"*50)\n\nprint(f\"Gaussian Naive Bayes Accuracy: {accuracy_multinomial:.4f}\")\nprint(f\"Multinomial Naive Bayes Accuracy: {accuracy_multinomial:.4f}\")\n\nif accuracy_multinomial > accuracy_multinomial:\n    print(\"âœ“ Gaussian Naive Bayes performs better!\")\n    best_model = accuracy_multinomial\n    best_scaler = scaler\n    use_scaled = True\nelse:\n    print(\"âœ“ Multinomial Naive Bayes performs better!\")\n    best_model = accuracy_multinomial\n    best_scaler = scaler","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:36:42.907001Z","iopub.execute_input":"2025-09-24T07:36:42.907359Z","iopub.status.idle":"2025-09-24T07:36:42.914146Z","shell.execute_reply.started":"2025-09-24T07:36:42.907336Z","shell.execute_reply":"2025-09-24T07:36:42.913125Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nMODEL COMPARISON\n==================================================\nGaussian Naive Bayes Accuracy: 0.7726\nMultinomial Naive Bayes Accuracy: 0.7726\nâœ“ Multinomial Naive Bayes performs better!\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"np.random.seed(42)\nsample_indices = np.random.choice(len(X_test), min(10, len(X_test)), replace=False)\n\nprint(\"Sample predictions on test data:\")\nprint(\"-\" * 60)\nprint(f\"{'Actual':<10} {'Predicted':<10} {'Correct':<10}\")\nprint(\"-\" * 60)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:36:47.170845Z","iopub.execute_input":"2025-09-24T07:36:47.171156Z","iopub.status.idle":"2025-09-24T07:36:47.178748Z","shell.execute_reply.started":"2025-09-24T07:36:47.171135Z","shell.execute_reply":"2025-09-24T07:36:47.177401Z"}},"outputs":[{"name":"stdout","text":"Sample predictions on test data:\n------------------------------------------------------------\nActual     Predicted  Correct   \n------------------------------------------------------------\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"for idx in sample_indices:\n    if best_scaler:\n        sample = X_test_scaled[idx].reshape(1, -1)\n    else:\n        sample = (X_test_scaled[idx] - X_test_scaled.min() + 0.1).reshape(1, -1)\n    \n    actual = y_test.iloc[idx]\n      predicted = best_model.predict(sample)[0]\n    correct = \"âœ“\" if actual == predicted else \"âœ—\"\n    \n    print(f\"{actual:<10} {predicted:<10} {correct:<10}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if hasattr(best_model, 'theta_'):\n    print(\"\\n\" + \"=\"*50)\n    print(\"FEATURE IMPORTANCE (GaussianNB)\")\n    print(\"=\"*50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-24T07:37:31.940062Z","iopub.execute_input":"2025-09-24T07:37:31.941003Z","iopub.status.idle":"2025-09-24T07:37:31.945516Z","shell.execute_reply.started":"2025-09-24T07:37:31.940970Z","shell.execute_reply":"2025-09-24T07:37:31.944502Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"feature_importance = np.std(best_model.theta_, axis=0)\n    feature_names = X.columns\n    \n    importance_df = pd.DataFrame({\n        'Feature': feature_names,\n        'Importance': feature_importance\n    }).sort_values('Importance', ascending=False)\n    \n    print(importance_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ncm = confusion_matrix(y_test, best_model.predict(X_test_scaled if use_scaled else X_test_positive))\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=best_model.classes_, \n            yticklabels=best_model.classes_)\nplt.title('Confusion Matrix - Best Model')\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"FINAL SUMMARY\")\nprint(\"=\"*50)\nprint(f\"Best Model: {'Gaussian Naive Bayes' if accuracy_gaussian > accuracy_multinomial else 'Multinomial Naive Bayes'}\")\nprint(f\"Final Accuracy: {max(accuracy_gaussian, accuracy_multinomial):.4f}\")\nprint(f\"Number of training samples: {X_train.shape[0]}\")\nprint(f\"Number of test samples: {X_test.shape[0]}\")\nprint(f\"Number of features: {X_train.shape[1]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}